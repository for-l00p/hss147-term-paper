{"status":"OK","result":{"originalLocale":"en","allowViewHistory":true,"creationTimeSeconds":1458521076,"rating":88,"authorHandle":"DanAlex","modificationTimeSeconds":1502152342,"id":43911,"title":"\u003cp\u003eWhy so mainstream? the spinoff\u003c/p\u003e","locale":"en","content":"\u003cdiv class\u003d\"ttypography\"\u003e\u003cp\u003eAn intro would be also be kind of mainstream, but I\u0027ll still be...\u003c/p\u003e\u003ch2\u003eCutting to the chase\u003c/h2\u003e\u003cp\u003eRotations and balancing are kind of boring, but invariants are not. The nice thing about in looking for different solutions for the same problem is that you can find elegance in each of them. Maybe more importantly, it helps you develop backups when the first solution fails.\u003c/p\u003e\u003cp\u003eIt is just the fact that sometimes to sell and start over is the right call. Of course, starting off with a small amount of one million dollars would do(couldn\u0027t help myself, people keep saying orange is the new black (now seriously: I say Donald, you say... Knuth) \u0027\u003c/p\u003e\u003ch2\u003eBinary search tree\u003c/h2\u003e\u003cp\u003eThe problems is to implement the basic operations of a (STL\u0027s)set:\u003c/p\u003e \u003cul\u003e   \u003cli\u003eInsert\u003c/li\u003e   \u003cli\u003eDelete\u003c/li\u003e   \u003cli\u003eSearch\u003c/li\u003e   \u003cli\u003eLower bound\u003c/li\u003e   \u003cli\u003eUpper bound\u003c/li\u003e \u003c/ul\u003e\u003cp\u003eAnd so on...\u003c/p\u003e\u003cp\u003eThe obvious slow solution is as always a list. We will try to improve it and blah, blah, blah. This is not helpful at all. \u003c/p\u003e\u003cp\u003eThe lower and upper bounds keeps our attention. For those to be executed we need an order. A hash or whatever structure that keeps things unsorted is really hard to manage around this operation. Is the structure was static, binary search would have done the job. \u003c/p\u003e\u003cp\u003eFrom this point, I see some approaches:\u003c/p\u003e \u003cul\u003e   \u003cli\u003eleave gaps in a static structure\u003c/li\u003e   \u003cli\u003ework with chunks of data\u003c/li\u003e   \u003cli\u003etry to link data differently\u003c/li\u003e   \u003cli\u003ework around binary search and make a structure that does it dynamically(that goes to BST)\u003c/li\u003e \u003c/ul\u003e\u003cp\u003eI will focus on the last one, but all of them lead to interesting stuff. You can try to look up skiplists, for example.\u003c/p\u003e\u003cp\u003eNow, how binary works is that it looks first at the middle and then at another middle and so on. What if our structure does the exact same thing? If you draw a decision tree for a binary search, the thing that happens is that you put the middle in the top, then the middle of the left interval in left, the middle of the right interval in right and so on.\u003c/p\u003e\u003cp\u003e\u003cimg alt\u003d\" \" src\u003d\"/predownloaded/9d/1c/9d1cd2aab443d746ff7946b423da69628984094e.png\" style\u003d\"max-width: 100.0%;max-height: 100.0%;\" /\u003e\u003c/p\u003e\u003cp\u003eThe cool things that we observe here are that:\u003c/p\u003e \u003cul\u003e   \u003cli\u003ethe tree is balanced\u003c/li\u003e   \u003cli\u003eall element in the left of a node are smaller that node and those in the right bigger\u003c/li\u003e \u003c/ul\u003e\u003cp\u003e\u003cem\u003eThe BST is a binary tree that respects the second property.\u003c/em\u003e\u003c/p\u003e\u003cp\u003eFinding a structure that respects this property is not that hard(for example an ordered list works), but the thing that makes the decision tree above is the so called balance. Firstly, let\u0027s look why BST operations work good on average case and then try to add more invariants to make the structures good every time.\u003c/p\u003e\u003ch4\u003eSearching\u003c/h4\u003e\u003cp\u003eThe search is straight forward. We look is the current node is what we are looking for, otherwise look in which part should we go. Here is some (stolen)code just to be clear:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003efunction search(node, value) {\n    if (!node || node.value \u003d\u003d value) {\n        return node;\n    } else {\n        if (node.value \u0026gt; value) {\n            return search(node.left, value);\n        } else {\n            return search(node.right, value);\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch4\u003eInsert\u003c/h4\u003e\u003cp\u003eInsertion goes just as the search. When we reach a null value, we insert a new node in the tree. \u003c/p\u003e \u003cpre\u003e\u003ccode\u003eNode* insert(Node* node, int value) {\n    if (!node) {\n        return new Node(value);\n    } else if (key \u0026lt; node-\u0026gt;value) {\n        node-\u0026gt;left \u003d insert(node-\u0026gt;left, value);\n    } else  \n        node-\u0026gt;right \u003d insert(node-\u0026gt;right, value);\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe reason we used a pointer for the node is that we want to actually modify the reference from the father of the new inserted leaf.\u003c/p\u003e\u003ch4\u003eDelete\u003c/h4\u003e\u003cp\u003eFirst search the tree to find the node that we have to delete. Now we have just to tackle the case when we have to delete the root. We need a node that we can put as a the new root. That is the biggest element from the left subtree. This is the rightmost element of the left subtree.\u003c/p\u003e\u003cp\u003e\u003cimg alt\u003d\" \" src\u003d\"/predownloaded/14/96/1496cb771cc7cbad9d7ba39e1c588f57b155aadc.png\" style\u003d\"max-width: 100.0%;max-height: 100.0%;\" /\u003e\u003c/p\u003e \u003cpre\u003e\u003ccode\u003edef binary_tree_delete(self, key):\n    if key \u0026lt; self.key:\n        self.left_child.binary_tree_delete(key)\n    elif key \u0026gt; self.key:\n        self.right_child.binary_tree_delete(key)\n    else: # delete the key here\n        if self.left_child and self.right_child: \n            successor \u003d self.right_child.find_min()\n            self.key \u003d successor.key\n            successor.binary_tree_delete(successor.key)\n        elif self.left_child:  \n            self.replace_node_in_parent(self.left_child)\n        elif self.right_child:  \n            self.replace_node_in_parent(self.right_child)\n        else: # this node has no children\n            self.replace_node_in_parent(None)\n\u003c/code\u003e\u003c/pre\u003e\u003ch2\u003eTreaps\u003c/h2\u003e\u003cp\u003eNow, as I have mentioned, the BST is good on average. A (dirty) hack is just to try to somehow keep this randomness. If we change the order of the tasks we blow thing up. Instead we will add an additional value to each node(call it key) and some other invariant.\u003c/p\u003e\u003cp\u003eThe treap is a BST and a heap. In order for us to go forward we have to define right and left rotations. Suppose I have the following tree with nodes P and Q and subtrees A, B and C. If B and C have depth S and A has depth S+1, then this operation will give decrease the depth of the whole tree. This operation and its reverse are called left and right rotations. \u003c/p\u003e\u003cp\u003e\u003cimg alt\u003d\" \" src\u003d\"/predownloaded/3a/cc/3accaafaabb00f8170374fe13d35c5226124a8c8.png\" style\u003d\"max-width: 100.0%;max-height: 100.0%;\" /\u003e\u003c/p\u003e\u003cp\u003eMore formally, the treap has two invariants:\u003c/p\u003e \u003cul\u003e   \u003cli\u003eAll values in the left of a node are smaller the value of that node and those in the right are bigger.\u003c/li\u003e   \u003cli\u003eThe keys of each node are bigger than the keys of the children.\u003c/li\u003e \u003c/ul\u003e\u003cp\u003eEach time we insert a node, we will generate a random key and insert the node just as in the BST. While the node key is bigger then the one of the father, we keep rotating(left or right) to get the node up.\u003c/p\u003e\u003cp\u003eWhen we want to delete a node, we move it to the bottom of the tree by rotations and deleting a leaf is trivial. Also, note that during each step of any algorithm the only invariant that is broken(and tried to be fixed) is the heap one. The rotations preserve the order of the tree. This together with the depth reduction kind of tells us that this operation has the potential of keeping the tree balanced.\u003c/p\u003e\u003ch2\u003eAVL trees\u003c/h2\u003e\u003cp\u003eA random fact good to know is that just as you, average reader, the abbreviation is not special.(it is made out of the names of the guys who made the structure) Now, the left and right rotations can add or decrease the height of a tree if either of the lower subtrees has size bigger than the upper one. But if one is bigger you have to admit that some imbalance will still remain. Life is not perfect.\u003c/p\u003e\u003cp\u003eFortunately, life is nice, so we can keep just a slight equilibrium. Let\u0027s denote the equilibrium factor as the difference of depth between the left and the right subtrees of a node. We want to keep the equilibrium factor between -1 and 1. Now, this will be broken if any node\u0027s equilibrium factor is -2 or 2. We always start with an equilibrated balance factor so we have to track only 4 cases. The following image shows gives quite an accurate description:\u003c/p\u003e\u003cp\u003e\u003cimg alt\u003d\" \" src\u003d\"/predownloaded/15/d7/15d7c0adac6e0a0cbba148d045c18e4d7108688a.png\" style\u003d\"max-width: 100.0%;max-height: 100.0%;\" /\u003e\u003c/p\u003e\u003cp\u003eThe equilibrium factor holds between -1 and 1 for each subtree A, B, C and D because it was held there before the current step. This procedure is called balancing and it will be called at each modification in the BST. This will yeld us a \u003cspan class\u003d\"tex-span\"\u003e\u003ci\u003eO\u003c/i\u003e(\u003ci\u003elog\u003c/i\u003e \u003ci\u003eN\u003c/i\u003e)\u003c/span\u003e complexity overall. In the case of the insertion, the first node the can be broken is the grandparent of the inserted node. But now we have to check for the grandparent\u0027s dad. Why? After the rotation the height of 3 or 5(last picture) node might have increased/decreased. Therefore the father of node 4 might find a factor increase/decrease of 1. The deletion will be treated in a similar manner.\u003c/p\u003e\u003ch2\u003eConclusion\u003c/h2\u003e\u003cp\u003eI tried to put empathy on the different approaches to solve the same problem, not on the structures themselves. The first set of observations made in BST section can get us to other funny nice structures(skiplists for example). The balance can be achieved with different sets of invariants. A good example is the red-black tree. \u003c/p\u003e\u003ch4\u003ePS\u003c/h4\u003e\u003cp\u003eIn fact I think the title was quite uninspired.\u003c/p\u003e\u003cp\u003eThank you for reading and please state your opinion on my tutorial. (or, more specifically, on my writing style and how useful you find the material presented) Any suggestions for next tutorial are welcome.\u003c/p\u003e\u003cp\u003eYou can find my previous article \u003ca href\u003d\"//codeforces.com/blog/entry/23302\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eHope you enjoyed!\u003c/p\u003e\u003c/div\u003e","tags":[]}}
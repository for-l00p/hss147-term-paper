{"status":"OK","result":{"originalLocale":"en","allowViewHistory":true,"creationTimeSeconds":1435852891,"rating":35,"authorHandle":"Enchom","modificationTimeSeconds":1435852891,"id":19037,"title":"\u003cp\u003eBalkan Olympiad in Informatics — Day 2\u003c/p\u003e","locale":"en","content":"\u003cdiv class\u003d\"ttypography\"\u003e\u003cp\u003eThe second day of the Balkan Olympiad in Informatics has finished and the competition went pretty smoothly, there was a minor bug in the tests of the second problem, but it was fixed quickly.\u003c/p\u003e\u003cp\u003e\u003ca href\u003d\"http://www.boi2015.uni-ruse.bg/competition/results\"\u003eFinal results\u003c/a\u003e\u003c/p\u003e\u003cp\u003eThe tasks in the second day were, in my opinion, more interesting than the first day. Once again here\u0027s a link with the problems (from both days):\u003c/p\u003e\u003cp\u003e\u003ca href\u003d\"http://www.boi2015.uni-ruse.bg/competition/tasks\"\u003eTasks\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eClarkson\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThis problem was quite interesting and the solution was based on a suffix structure. Both suffix array and suffix tree were good enough to solve the problem, and building them for O(N log N) or perhaps even O(N log^2 N) was sufficient. The structure was used so you can calculate the function:\u003c/p\u003e\u003cp\u003eF[i] — the largest substring in the first string, starting at index i, that is present in the second string.\u003c/p\u003e\u003cp\u003eAfter this function was computed, binary search for the answer combined with dynamic programming was enough to solve the problem in O(N log N), making the total complexity O(N log N) assuming the suffix structure is built fast enough.\u003c/p\u003e\u003cp\u003e\u003cem\u003eFun fact : I actually practiced my suffix trees right before the first competition day as the last BOI had a problem that involved suffix structures and I wasn\u0027t able to solve it because I couldn\u0027t build a suffix tree/array, and I was worried it might happen again :)\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eRadio\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThis was the hardest problem of the day and one of the best in the competition. Here is my solution in summary:\u003c/p\u003e\u003cp\u003eLet\u0027s imagine each tower as a segment [X-P; X+P]. Obviously our goal is to increase the P of the chosen subset in such a way, so that each pair of chosen intervals will overlap or touch. It is easy to see that this means that all of the chosen intervals will have at least one common point, that is, there will be a point that belongs to all intervals. Let\u0027s call this the \u0026quot;middle\u0026quot; point. Fixing the middle point gives an easy linear computation of the cost.\u003c/p\u003e\u003cp\u003eThis gives the idea for solution with N\u003dK. However we can\u0027t try all 10^9 positions, so we have to make the following observation: It is sufficient to try interval endings to be middle points. I will not prove it, I believe it is easy enough to see. This gives us straightforward O(N^2) solution.\u003c/p\u003e\u003cp\u003eTo speed it up we can break down intervals to beginnings and ends, and process them as events going from left to right. Keeping some proper values, one can easily speed it up to O(N log N) in total, which gives 45 points (subtasks 1, 2 and 4).\u003c/p\u003e\u003cp\u003eFor subtasks with Si\u003d1, I am not sure what the intended solution was, but from what I understood it has to do with finding a median point as it will always be the best choice for a middle point.\u003c/p\u003e\u003cp\u003eFinally, for the final subtask one again has to process endpoints as events from left to right, however keeping a few priority queues is necessary. I call \u0026quot;active\u0026quot; those towers that I will preserve, and \u0026quot;unactive\u0026quot; those that will be sold. Then at all times I keep 4 sets/priority queues:\u003c/p\u003e\u003cp\u003e1) RightUnactive — all unactive towers whose beginning hasn\u0027t been processed\u003c/p\u003e\u003cp\u003e2) MiddleUnactive — all unactive towers whose beginning has been processed, but whose ending hasn\u0027t\u003c/p\u003e\u003cp\u003e3) MiddleActive — all active towers whose beginning has been processed, but whose ending hasn\u0027t\u003c/p\u003e\u003cp\u003e4) LeftActive — all active towers whose both beginning and end has been processed\u003c/p\u003e\u003cp\u003eIt turns out that after processing a new endpoint, only a few changes can occur in those sets, and the sets can be easily updated if they are sorted in the right way. I will not go into details as my solution was quite long. The total complexity should be O(N log N) and worked in 0.2s on the largest testcase.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eTiling\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eFinally this was a tricky problem if you wanted to prove your solution. The crucial observation was that you had to break the grid into L*K squares of size NxN, and query once in each (I\u0027m not sure if it mattered which cell in each square, I used center cells) and then the answer always gave an unique solution and was minimal in respect to queries. Proving that is difficult as far as I know, but it wasn\u0027t necessary, quite a few people managed to find out that these are the optimal queries.\u003c/p\u003e\u003cp\u003eProbably the harder thing was actually finding the tiles\u0027 layout. I used backtracking with optimizations so that some \u0026quot;obvious\u0026quot; tiles were put before the backtracking, but sadly I spent too much time on problem 2 and couldn\u0027t finish my optimizations, hence 70/100.\u003c/p\u003e\u003cp\u003eThe surprising thing was that the intended solution was a quick way to place the tiles without backtracking (as backtracking should be exponential?), but almost all competitors managed to pass with the backtracking. I do not know the quick way so maybe someone can find out how it works?\u003c/p\u003e\u003cp\u003eMedals distribution will be announced tomorrow at the official closing ceremony, thanks for reading :)\u003c/p\u003e\u003c/div\u003e","tags":[]}}
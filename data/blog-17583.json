{"status":"OK","result":{"originalLocale":"ru","allowViewHistory":false,"creationTimeSeconds":1430068682,"rating":75,"authorHandle":"taras.klaskovsky","modificationTimeSeconds":1430071032,"id":17583,"title":"\u003cp\u003eVK cup wildcard round 2: Антиплагиат -- post your approach\u003c/p\u003e","locale":"ru","content":"\u003cdiv class\u003d\"ttypography\"\u003e\u003cp\u003eПривет,\u003c/p\u003e\u003cp\u003eна топкодерах принято после марафонов делать топик с post your approach и писать вкратце идеи решения и это весьма полезно как для участников так и сочувствующих, особенно топовые решения. (Я уточнил у Майка и он не возражает против обсуждения, если не постить код).\u003c/p\u003e\u003cp\u003eМне особенно интересен вопрос реиспользования кода, я смотрел с большой надеждой на всякие библиотечки по построению синтаксических деревьев или байткода(привет llvm) или хотя бы автоформатирования кода, но они были все на плюсах, огромные и с зависимостями, поэтому я велосипедил на джаве.\u003c/p\u003e\u003cp\u003eТак же должны быть наверняка крутые статьи по теме, но то что я бегло нашел касалось более high-scale подходов для тысяч документов.\u003c/p\u003e\u003cp\u003eЯ занял третье место. \u003c/p\u003e\u003cp\u003eЗаслав простое решение я понял что сплагиаченные решения сильно похожи и простые подходы набирают много баллов, поэтому мой high-level подход выглядит так:\u003c/p\u003e\u003cp\u003e1) Нормализовать код\u003c/p\u003e\u003cp\u003e2) Искать совпадающие последовательности команд в обоих решениях для каждой пары и если их много, значит плагиат. Причем совпадение очень нечеткое, с возможностью пропуска команды или небольших изменениях, из расчета что код читеров слегка пошафлен, но функции те же.\u003c/p\u003e\u003cp\u003e3) Разбить на компоненты связности плагиата и вывести их.\u003c/p\u003e\u003cp\u003eПодробнее,\u003c/p\u003e\u003cp\u003e1) Нормализация кода состоит из замены простых дефайнов, удаление табов, комментариев, импортов, добавления ровно одного пробела между токенами, новой строки после \u0026quot;;\u0026quot;, выпиливания стандартных классов CHelper\u0027а, удаления глупых слов вроде спецификаторов доступа и последним шагом замена всех слов на одну букву и всех чисел на другую. При таком процессе несомненно теряется много индивидуальности, которую было бы круто сохранить, но чтобы хорошо потестить комбинацию из нескольких классификаторов нужно было явно больше тестов.\u003c/p\u003e\u003cp\u003e2) Совпадение последовательностей эволюционировало до такого монстра: для каждой команды из первого файла(в нормализованном виде) мы ищем абсолютно такие же команды в втором файле, а потом для каждой такой пары смотрим на следующие восемь команд из первого файла и если для хотя бы шести из них можно найти нечеткую копию(одна ошибка при сравнение двух нормализованных строчек допустима) недалеко от исходной команды во втором файле, то значит это грубо говоря одинаковый блок и первый файлик получает +1 к подозрительности. \u003c/p\u003e\u003cp\u003eЕсли подозрительность достигает 49% от числа операторов в файлике то мы считаем два файла плагиатом.\u003c/p\u003e\u003cp\u003eПонятно что это не так сложно обмануть, но решения, которые не делают байткод сильно ограничены by design и тут много не сделаешь.\u003c/p\u003e\u003cp\u003eДля тестирования я скачал 50к решений и принтил в файлик все пары, которые были близки к границе согласно моему классификатору, крутил ручки, чтобы это было лучше и приходил в уныние. \u003c/p\u003e\u003cp\u003eСпасибо и интересно, кто к чему пришел и как все это тестил)\u003c/p\u003e\u003c/div\u003e","tags":["vk cup 2015","wildcard round 2","post your approach","а я выиграл маечку"]}}
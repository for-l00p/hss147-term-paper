{"status":"OK","result":{"originalLocale":"en","allowViewHistory":true,"creationTimeSeconds":1496272905,"rating":115,"authorHandle":"ItsNear","modificationTimeSeconds":1496339343,"id":52305,"title":"\u003cp\u003eMaking machines write and execute code #1: Neural programmer-interpreters\u003c/p\u003e","locale":"en","content":"\u003cdiv class\u003d\"ttypography\"\u003e\u003cp\u003eHi, everyone,\u003c/p\u003e\u003cp\u003eAs I mentioned in the last post, myself and a friend of mine got very interested in how close we can get machines to writing software, and whether modern advances in Deep Learning can help us build tools that considerably improve the way people write, review and debug code.\u003c/p\u003e\u003cp\u003eI want to start a series of posts discussing some interesting advances in using machine learning for both writing and executing code.\u003c/p\u003e\u003cp\u003eThis particular post is about a machine learning model proposed early last year by Scott Reed from University of Michigan, then an intern at Google DeepMind, called \u003ca href\u003d\"https://arxiv.org/pdf/1511.06279.pdf\"\u003eNeural Programmer-Interpreters\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eBut before I go into the details, I would like to start with an ask. CodeForces and similar websites today host a vast amount of data that we would love to use to train our machine learning models. A particular challenge is that problem statements historically contain a lot of unnecessary information in an attempt to entertain competitors. Machine Learning models do not get entertained, but rather get very confused. We want to rewrite all the statements of all the problems available on the Internet in a very concise manner, so that a machine learning model has a chance of making sense of them. Thanks to people who volunteered after the last post, we now have more or less tested our labeling platform, and would like to invite everybody to help us create that dataset.\u003c/p\u003e\u003cp\u003eThe platform is located here:\u003c/p\u003e\u003cp\u003e\u003ca href\u003d\"https://r-nn.com/\"\u003ehttps://r-nn.com/\u003c/a\u003e\u003c/p\u003e\u003cp\u003eThere\u0027s a monetary reward associated with labeling the solutions. Based on my own performance, and performance of those people who helped us with testing, after some practice it takes on average 2 to 4 minutes to write one short statement, which ends up paying around $6/hour. Something reasonable to consider for those who practice for upcoming competitions and don\u0027t have time for a full time job. On top of that, participating in the project is a great way to contribute to pushing science forward.\u003c/p\u003e\u003cp\u003eNow, back to the actual topic of the article.\u003c/p\u003e\u003ch1\u003eNeural Programmer-Interpreters\u003c/h1\u003e\u003cp\u003eNeural programmer-interpreter, or NPI for short, is a machine learning model that learns to execute programs given their execution traces. This is different from some other models, such as Neural Turing Machines, that learn to execute programs only given example input-output pairs.\u003c/p\u003e\u003cp\u003eInternally NPI is a recurrent neural network. If you are unfamiliar with recurrent neural networks, I highly recommend reading this article by Andrej Karpathy, that shows some very impressive results of very simple recurrent neural networks: \u003ca href\u003d\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\"\u003eThe Unreasonable Effectiveness of Recurrent Neural Networks\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eThe setting in which NPI operates consists of an environment in which a certain task needs to be executed, and some low level operations that can be performed in such environment. For example, a setting might comprise:\u003c/p\u003e \u003cul\u003e   \u003cli\u003eAn environment as a grid in which each cell can contain a digit; and a cursor in each row of the grid pointing to one of the cells;\u003c/li\u003e   \u003cli\u003eA task of adding up two multidigit numbers;\u003c/li\u003e   \u003cli\u003eLow-level operations including \u0026quot;move cursor in one of the rows\u0026quot; and \u0026quot;write a digit\u0026quot;:\u003c/li\u003e \u003c/ul\u003e\u003cp\u003e\u003cimg src\u003d\"http://www-personal.umich.edu/~reedscot/project_files/add.gif\" style\u003d\"max-width: 100.0%;max-height: 100.0%;\" /\u003e\u003c/p\u003e\u003cp\u003eGiven an environment and low-level operations, one can define high level operations, similar to how we define methods in our programs. A high level operation is a sequence of both low-level and high level operations, where the choice of each operation depends on the state of the environment. While internally such high level operations might have branches and loops, those are not known to the NPI. NPI is only given the execution traces of the program. For example, consider a maze environment, in which a robot is trying to find an exit, and uses low-level operations \u003ccode\u003eLOOK_FORWARD\u003c/code\u003e, \u003ccode\u003eTURN_LEFT\u003c/code\u003e, \u003ccode\u003eTURN_RIGHT\u003c/code\u003e and \u003ccode\u003eGO_STRAIGHT\u003c/code\u003e. A high level operation \u003ccode\u003emake_step\u003c/code\u003e can be of a form:\u003c/p\u003e \u003cpre\u003ehas_wall \u003d LOOK_FORWARD\nif (has_wall)\n    with 50% chance: TURN_RIGHT\n    else: TURN_LEFT\nelse: GO_STRAIGHT\u003c/pre\u003e\u003cp\u003eIf NPI was then to learn another high level operation that just continuously calls to \u003ccode\u003emake_step\u003c/code\u003e, the data that is fed to it would be some arbitrary rollout of the execution, such as\u003c/p\u003e \u003cpre\u003emake_step\n    LOOK_FORWARD\n    TURN_RIGHT\nmake_step\n    LOOK_FORWARD\n    GO_STRAIGHT\nmake_step\n    LOOK_FORWARD\n    GO_STRAIGHT\nmake_step\n    LOOK_FORWARD\n    TURN_LEFT\nmake_step\n    LOOK_FORWARD\n    GO_STRAIGHT\u003c/pre\u003e\u003cp\u003eIn other words, NPI knows what high level operations call to what low/high level operations, but doesn\u0027t know how those high level operations choose what to call in which setting. We want NPI by observing those execution traces to learn to execute programs in new unseen settings of the environment.\u003c/p\u003e\u003cp\u003eImportantly, we do not expect NPI to produce the original program that was used to generate execution traces with all the branches and loops. Rather, we want NPI to execute programs directly, but producing traces that have the same structure as the traces that were shown to NPI during training. For example, look at the far right block on the image above, where NPI emits high level operations for addition. It emits the same high level operations that the original program would have emitted, and then the same low level operations for each of them, but it is unknown how exactly it decides what operation to emit when, the actual program is not produced.\u003c/p\u003e\u003ch2\u003eHow is NPI trained?\u003c/h2\u003e\u003cp\u003eAn NPI is a recurrent neural network. A recurrent neural network is a model that learns an approximation of a function that gets a sequence of varying length as an input, and produces a sequence of the same length as an output. In its simplest form a single step of a recurrent neural network is defined as a function:\u003c/p\u003e \u003cpre\u003edef step(X, H):\n    Y_out \u003d tanh(A1 * (X + H) + b1)\n    H_out \u003d tanh(A2 * (X + H) + b2)\n    return Y_out, H_out\u003c/pre\u003e\u003cp\u003eHere \u003ccode\u003eX\u003c/code\u003e is the input at the corresponding timestep, and \u003ccode\u003eH\u003c/code\u003e is the value of \u003ccode\u003eH_out\u003c/code\u003e from the previous step. Before the first timestamp \u003ccode\u003eH\u003c/code\u003e is initialized to some default value, such as all zeros. \u003ccode\u003eY_out\u003c/code\u003e is the value computed for the current time step. It is important to notice that \u003ccode\u003eY\u003c/code\u003e at a particular step only depends on \u003ccode\u003eX\u003c/code\u003es up to that timestep, and that the function that computes \u003ccode\u003eY\u003c/code\u003e is differentiable with respect to all \u003ccode\u003eA\u003c/code\u003es and \u003ccode\u003eb\u003c/code\u003es, so those parameters can be learned with back propagation.\u003c/p\u003e\u003cp\u003eSuch a simple recurrent neural network has many shortcomings, one most important one is that the gradient of \u003ccode\u003eY\u003c/code\u003e with respect to parameters goes to zero very quickly as we go back across timestamps, and as such long term dependencies cannot be learned in any reasonable time. This problem is solved by more sophisticated \u003ccode\u003estep\u003c/code\u003e functions, two most widely used are \u003ccode\u003eLSTM\u003c/code\u003e (long-short term memory) and \u003ccode\u003eGRU\u003c/code\u003e (gated recurrent units). Importantly, while the actual way \u003ccode\u003eY_out\u003c/code\u003e and \u003ccode\u003eH_out\u003c/code\u003e are computed in \u003ccode\u003eLSTM\u003c/code\u003es and \u003ccode\u003eGRU\u003c/code\u003es differ from the above \u003ccode\u003estep\u003c/code\u003e function, conceptually they are the same in the sense that they take the current \u003ccode\u003eX\u003c/code\u003e and the previous hidden state \u003ccode\u003eH\u003c/code\u003e as input, and produce \u003ccode\u003eY\u003c/code\u003e and the new value of \u003ccode\u003eH\u003c/code\u003e as an output.\u003c/p\u003e\u003cp\u003eNPI, in particular, uses \u003ccode\u003eLSTM\u003c/code\u003e cells to avoid the vanishing gradient problem. The input to the NPI\u0027s LSTM at each timestamp is the observation of the environment (such as the full state of the grid with all the cursor positions for the addition problem), as well as some representation of the high level operation that is being executed. The output is either a low-level operation to be executed, a high-level operation to be executed, or an indication to stop. If it\u0027s a low-level operation, it is immediately executed in the environment, and the NPI moves to the next timestamp, feeding the new state of the environment as the input. If it\u0027s an indication to stop, the execution of the current high level operation is terminated.\u003c/p\u003e\u003cp\u003eIf LSTM, however, has emitted a high level operation, the execution is more complex. First, NPI remembers the value of the hidden state \u003ccode\u003eH\u003c/code\u003e after the current timestamp was evaluated, let\u0027s call it \u003ccode\u003eh_last\u003c/code\u003e. Then a brand new LSTM is initialized, and is fed \u003ccode\u003eh_last\u003c/code\u003e as its initial value of \u003ccode\u003eH\u003c/code\u003e. This LSTM is then used to recursively execute the emitted high level operation. When the newly created LSTM finally terminates, its final hidden state value is discarded, the original LSTM is resumed again, and executes it\u0027s next timestamp, receiving \u003ccode\u003eh_last\u003c/code\u003e as the hidden state.\u003c/p\u003e\u003cp\u003eThe overall architecture is shown in this picture:\u003c/p\u003e\u003cp\u003e\u003cimg src\u003d\"/predownloaded/0c/2b/0c2b1f8c4b0e817bc7ae05927c59435de177ad7d.png\" style\u003d\"max-width: 100.0%;max-height: 100.0%;\" /\u003e\u003c/p\u003e\u003cp\u003eWhen the NPI is trained, the emitted low-level or high-level operation is compared to that produced by the actual program to be learned, and if they do not match, the NPI is penalized. Whenever NPI fails to properly predict the operation to be executed during training, there\u0027s a question whether we should execute in the environment the correct operation from the actual execution trace we are feeding, or the operation that the NPI predicted. The motivation behind executing the correct operation is that if we feed predicted operations (which early on during training are mostly meaningless), the error in the environment accumulates, and the NPI has no chance of predicting consecutive operations correctly. The motivation behind feeding the predicted operations is that after the NPI is trained, during evaluation it will always be fed the predicted operations (since the correct ones are not known), and so feeding the correct ones during training makes the model to be trained in a setting that is different from the setting in which it will be evaluated. While there\u0027s a good technique that addresses this issue called \u003ca href\u003d\"https://arxiv.org/pdf/1506.03099.pdf\"\u003eScheduled Sampling\u003c/a\u003e, NPI doesn\u0027t use it, and always executes the correct operation in the environment during training, disregarding the predicted one.\u003c/p\u003e\u003cp\u003eIn the original paper the NPIs are tested on several toy tasks, including the addition described above, as well as a car rotation problem where the input to the neural network is an image of a car, and the network needs to bring it into a specific state via a sequence of rotate and shift operations:\u003c/p\u003e\u003cp\u003e\u003cimg src\u003d\"http://www-personal.umich.edu/~reedscot/project_files/cars.gif\" style\u003d\"max-width: 100.0%;max-height: 100.0%;\" /\u003e\u003c/p\u003e\u003cp\u003eWith both toy tasks NPI achieves nearly perfect success rate. However, NPIs are rather impractical, since one needs the execution traces to train them, meaning that one needs to write the program himself before being able to learn it. Other models such as Neural Turing Machines are more interesting from this perspective, since they can be trained from input-output pairs, so one doesn\u0027t need to have an already working program. I will talk about Neural Turing Machines, and their more advanced version Neural Differentiable Computer, in one of the next posts in this series.\u003c/p\u003e\u003ch2\u003eProvably correct NPIs and Recursion\u003c/h2\u003e\u003cp\u003eOne of the problems with NPIs is that we can only measure the generalization by running the trained NPI on various environments and observing the results. We can\u0027t, however, prove that the trained NPI perfectly generalizes even if we observe 100% generalization on some sample environments.\u003c/p\u003e\u003cp\u003eFor example, in the case of multidigit addition the NPI might internally learn to execute a loop and add corresponding digits, however over time a small error in its hidden state can accumulate and result in errors after many thousands of digits.\u003c/p\u003e\u003cp\u003eA new paper that was presented on ICLR 2017 called \u003ca href\u003d\"https://people.eecs.berkeley.edu/~dawnsong/papers/iclr_2017_recursion.pdf\"\u003eMaking Neural Programming Architecture Generalize Via Recursion\u003c/a\u003e addresses this issue by replacing loops in the programs used to generate execution traces with recursion. Fundamentally nothing in the NPI architecture prevents one from using recursion -- during the execution of a high level operation \u003ccode\u003eA\u003c/code\u003e the LSTM can theoretically emit the same high level operation, or some other high level operation \u003ccode\u003eB\u003c/code\u003e that in turn emits \u003ccode\u003eA\u003c/code\u003e. In other words, the model used in the 2017 paper is identical to the model used in the original Scott Reed\u0027s paper, the difference is only in the programs used to generate the execution traces. Since in the new paper the execution traces are generated by programs that contain no loops, execution of any high level operation under perfect generalization should yield a bounded number of steps, which means that we can prove that the trained NPI has generalized perfectly by induction if we can show that it emits correct low level commands for all the base cases, and emits correct bounded sequences of high and low level commands for all possible states of relevant part of the environment.\u003c/p\u003e\u003cp\u003eFor example, in the example of multidigit addition, it is sufficient to show that the NPI properly terminates when no more digits are available (the environment has no digits under cursors and \u003ccode\u003eCARRY\u003c/code\u003e is zero), and that the NPI correctly adds up two numbers and recurses to itself for any pair of digits under cursor and state of the \u003ccode\u003eCARRY\u003c/code\u003e. Authors of the paper show that for recursive addition algorithm an NPI trained only on examples up to five digits long provably generalizes for arbitrarily long numbers.\u003c/p\u003e\u003cp\u003eHope it was interesting. In the next post I will switch from learning how to execute programs to learning how to write them, and will show a nice demo of a recurrent neural network that tries to predict next few tokens as the programmer writes a program.\u003c/p\u003e\u003c/div\u003e","tags":["neural networks"]}}
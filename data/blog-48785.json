{"status":"OK","result":{"originalLocale":"ru","allowViewHistory":false,"creationTimeSeconds":1480691756,"rating":486,"authorHandle":"MikeMirzayanov","modificationTimeSeconds":1480693296,"id":48785,"title":"\u003cp\u003eSad story about rescheduling on the Round 383\u003c/p\u003e","locale":"en","content":"\u003cdiv class\u003d\"ttypography\"\u003e\u003cp\u003eGood afternoon.\u003c/p\u003e\u003cp\u003eSorry. Unfortunately, today (on Friday) we can\u0027t run the round 383 :-(\u003c/p\u003e\u003cp\u003eIn short, this is because of technical reasons. For those interested in a more detailed description option.\u003c/p\u003e\u003cp\u003eOn Thursday night I got sms. It was written that on server for DB backups free HDD space is less than 10%. This server stores three copies of the database over the last three days. It has 2TB drive and Codeforces database over 600GB now.\u003c/p\u003e\u003cp\u003eSince the next day I had planned to spend on the train on the way to NEERC, I decided to delete some redundant data from the DB. I estimate it will give several tens of gigabytes of free space.\u003c/p\u003e\u003cp\u003eI run query to remove redundant data and it was a mistake. I seems because of huge table to update (tens millions of rows) estimated time for the query to compete was at least several hours. As a result, I have killed this query, making KILL QUERY. But the database has continued to lag, I decided to restart it. Operation to shutdown the DB hanged for ~2 hours (I think it was rolling back the transaction), and the DB has stopped to respond and has become quite sad. As a result, I killed the DB process in the operating system and the database already refused to start without a recovery operation, which is also wasn\u0027t completed in a couple of hours. In short, I have struggled with this from 5 am to 9 am.\u003c/p\u003e\u003cp\u003eTo make Codeforces live I reconfigured it to use database replica in the remote datacenter (in Mail.Ru). Before boarding the train, I started the process of transferring data from the replica back, but contrary to my expectations, this process has been very slow.\u003c/p\u003e\u003cp\u003eIt is impossible to run the round using a remote reserve database server. Therefore, we have to move the round forward to Tuesday.\u003c/p\u003e\u003cp\u003eMy apologies. I spent many hours struggling with technical issues and worked up to the last. However, it seems the bottleneck is in speed of data transmission over a network, in the speed to write on HDD and in the speed of innobackupex utility.\u003c/p\u003e\u003cp\u003eI hope that on Tuesday everything will go fine!\u003c/p\u003e\u003cp\u003eMikeMirzayanov\u003c/p\u003e\u003c/div\u003e","tags":["383"]}}
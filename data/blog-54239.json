{"status":"OK","result":{"originalLocale":"ru","allowViewHistory":true,"creationTimeSeconds":1504290911,"rating":-36,"authorHandle":"EnigmaWasp","modificationTimeSeconds":1504290911,"id":54239,"title":"\u003cp\u003eСамостоятельное развертывание приложений без использования Kubernetes\u003c/p\u003e","locale":"ru","content":"\u003cdiv class\u003d\"ttypography\"\u003e\u003cp\u003eА что если ваши приложения будут обрабатывать самостоятельно свои собственные операционные системы? Это вроде как окончательная форма DevOps, верно? Его окончательная эволюция? Чаризард для DevOps, если хотите.\u003c/p\u003e\u003cp\u003eВдохновение, чтобы написать об этом, пришло от Kelsey Hightower, который прекрасно рассказал о саморазвитии приложений Kubernetes. \u003ca href\u003d\"https://www.youtube.com/watch?v\u003dXPC-hFL-4lU\"\u003ehttps://www.youtube.com/watch?v\u003dXPC-hFL-4lU\u003c/a\u003e Рекомендую к просмотру.\u003c/p\u003e\u003cp\u003eВот вам и TLDR; \u003cstrong\u003emyapp --kubernetes --replicas\u003d5\u003c/strong\u003e\u003c/p\u003e\u003cp\u003emyapp сам статирует для Linux, монтирует себя и развертывает себя в кластер Kubernetes с 5 репликами. Никаких файлов конфигурации не требуются.\u003c/p\u003e\u003cp\u003eЯ подумала, что это было бы очень круто, и тут же отправился проверять Kubernetes, чтобы посмотреть, могу ли я добавить что-то подобное Pilosa( \u003ca\u003ehttps://github.com/pilosa/pilosa)\u003c/a\u003e. В документации Kubernetes есть такая страница, посвященная «выбору правильного решения», которая имеет более 40 различных способов общения с Kubernetes, ни один из которых не «запускал этот двоичный файл». Я не хочу копаться в сомне страниц документации только для одного маленького быстрого эксперимента! Я знаю что Kubernetes это отличное программное обеспечение, и я готова поспорить, что скоро мы будем развертывать Pilosa в нашем собственном кластере Kubernetes. Однако в этот конкретный момент меня действительно поразила идея «саморазвертывания приложений», а не рутинная часть «на Kubernetes».\u003c/p\u003e\u003cp\u003eНа самом деле я осознала, что уже проделала определенную работу в этом направлении для бенчмаркинга Pilosa. Первоначальная идея заключалась в том, чтобы создать инструмент, который с помощью одной команды смог бы: Предоставлять облачную инфраструктуру различным провайдерам Устанавливать и запускать кластер Pilosa на удаленных хостах Позволит определить высоко настраиваемые тесты Устанавливать и запускать тесты на удаленных «агентовских» хостов Собирать результаты тестов Собирать метрики хоста (процессор, память и т.д.) Хранить все данные каждого теста в согласованном формате Готовить и подавать вкусняшки(шутка) В любом случае мы фактически достигли некоторых из этих целей с помощью нового инструмента Pi. Pi — это инструмент, специально предназначенный для бенчмаркинга Pilosa, но я думаю, что он содержит некоторые многоразовые библиотеки, которые могут быть полезны для сообщества с открытым исходным кодом в целом (с возможностью его улучшения). \u003c/p\u003e\u003cp\u003eЭто всё хорошо, но давайте вернемся к развертыванию приложений. Давайте отложим часть предоставления ресурсов из облака на данный момент, и скажем что у нас есть набор свежих, чистых, Linux-хостов, к которым есть ssh-доступ, и мы хотим непосредственно протестировать Pilosa. Допустим у вас есть локальная кодовая база Pilos (в вашем GOPATH), а также мифический инструмент Pi. Какова минимальная сумма работы, которую вы могли бы ожидать, чтобы запустить тест против кластера Pilosa и собрать результаты? Как насчет запуска одной команды на вашем ноутбуке в каком-нибудь переполненном кафе?\u003c/p\u003e\u003cp\u003e\u003cstrong\u003epi spawn --pilosa-hosts\u003d\u0026lt;...\u0026gt; --agent-hosts\u003d\u0026lt;...\u0026gt; --spawn-file\u003d~/my.benchmark\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eНажимаете на enter, и через несколько минут у вас данные бенчмаркинга прямо перед вами. Многоузловой кластер Pilosa был создан вместе с несколькими узлами агентов для отправки запросов к нему. Агенты извергли огромное количество реалистично распределенных случайных данных в кластер, а затем последовали за ним с помощью комплекса сложных запросов.\u003c/p\u003e\u003cp\u003eИмейте в виду, что до того, как вы запустили Pi, этот пул удаленных хостов знать не знает о Go, Pilosa, Pi или о чем либо еще. Это были просто изображения Linux с AWS или GCP или что-то подобное. Как мы это сделаем? Давайте разобьем процесс на этапы: во-первых, нам нужно иметь возможность подключаться к удаленным хостам через ssh изнутри программы Go. Приятный сюрприз, оказывается у Go есть довольно большой пакет ssh(\u003ca\u003ehttps://godoc.org/golang.org/x/crypto/ssh)\u003c/a\u003e, который обрабатывает большую часть этого вместо нас.\u003cbr /\u003eКак только мы подключаемся к удаленным хостам, мы можем выполнять команды в оболочке как с терминала! Мы получаем стандартные интерфейсы Reader и Writer для получения данных в этих командах и из них, поэтому всё очень хорошо. Но что мы собираемся запустить? У этих хостов нет установленных Pilosa или Pi, которые нам понадобятся, если мы хотим запустить кластер и протестировать его. Ну, давайте просто запустим dog — у этих хостов определенно есть это, не так ли? В частности, мы будем запускать dog \u0026gt; pilosa — помните про Writer? Это на самом деле io.WriteCloser, и он идет прямо на stdin dog. Поэтому мы просто пишем весь бинарный файл Pilosa прямо там, закрываем его, и данные магическим образом переносятся в файл на удаленном хосте! «Подождите», скажете вы. «Какой бинарный? Мой ноутбук в этой кофейне не имеет бинарного файла Linux для Pilosa.» Как вы, возможно, догадались, Go экономит день, сделав его легким для перекрестного компилирования для других платформ. Теперь я знаю, что вы думаете: «Он собирается импортировать пакеты для компилятора Go, строить новый диск Pilosa непосредственно в памяти и передавать его прямо в dog, работающую на удаленном хосте. Я НЕ МОГУ ЖДАТЬ! \u0026quot; Да, нет, извините — это тот самый парень, который не мог потрудиться, чтобы запустить виртуальную машину, чтобы испытать Kubernetes. Я посмотрела на источник для инструментальной цепочки в течение минуты и решила использовать os / exec для запуска сборки go в подпроцессе.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ecom :\u003d exec.Command(\u0026quot;go\u0026quot;, \u0026quot;build\u0026quot;, \u0026quot;-o\u0026quot;, \u0026quot;someTempFile\u0026quot;, \u0026quot;https://github.com/pilosa/pilosa\u0026quot;)\u003c/strong\u003e \u003cstrong\u003eАх да нам ведь нужно настроить среду, чтобы убедиться, что мы всё это дело создаем для Linux:\u003c/strong\u003e \u003cstrong\u003ecom.Env \u003d append(os.Environ(), \u0026quot;GOOS\u003dlinux\u0026quot;)\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eОткройте временный файл dog,поместите его на удаленный хост, с помощью chmod, чтобы сделать его исполняемым, и … работаем! Давайте уделим минутку для обдумывания того как много Go помогло нам там — не только придал легкость перекрестной компиляции, а еще учтем тот факт, что мы можем скомпилировать автономный бинарный файл, который довольно легковесный, и это пожалуй всё, что нам нужно для запуска нашего приложения на другом хосте. Никакой JVM, никакого переводчика — это действительно просто очень освежает — как добротный лимонад. Хорошо, бинарный файл Pilosa на своем месте. Мы можем создать файл конфигурации и скопировать его таким же образом или просто запустить Pilosa с аргументами командной строки. После того, как он будет запущен, мы сможем передать любые логи обратно нам или оставить их в файле на удаленном хосте.\u003c/p\u003e\u003cp\u003eТеперь настало время обратить внимание на поставленную задачу — бенчмаркинг. Говоря формально, мы еще не создали самораспространяющееся приложение, мы создали приложение для развертывания Pilosa — помните, что это Pi, который делает всё это дело. Но нам нужно запускать Pi на удаленных хостах, потому что у Pi есть все инструменты для бенчмаркинга, и нет никакой причины, по которым этот кросс-компиляционный dog не будет работать так же, как в исходном коде самой программы, которая его запускает. Мы перекрестно скомпилируем Pi, копируем его на каждый из «агентов» и выясним, какие тесты мы должны запускать, и запускаем их! Бенчмаркинг Pi сообщают о своих результатах в формате JSON на stdout, который мы счастливо собираем. Это немного странно, но опять же, мы обязаны за предоставленные нам модели параллелизма, которые делает всё очень простым. Мы запускаем несколько разных программ на нескольких удаленных хостах, которые бросают огромные объемы данных друг на друга и делают массовые вычисления. И всё это из одной программы на одном обычном ноутбуке с хиленьким Wi-Fi-соединением. Не говоря уже о том, что мы передаем потоки и объединяем результаты всех этих удаленных программ в единую сплоченную структуру результатов, которая полностью описывает бенчмаркинг. Это было бы кошмаром наяву для большинства языков! Вот, у вас на руках самораспространяющееся приложение без использования Kubernetes. Всё, что вам нужно, это куча хостов, к которым у вас есть доступ через SSH, и вы тоже можете создавать сложные флоты самораспространяющихся программ. Изучите исходный код для Pi (особенно пакеты build и ssh) и прочитайте документацию, если вы действительно хотите их использовать. Возможно, вы тоже сможете подкинуть пару патчей проекту.\u003c/p\u003e\u003c/div\u003e","tags":["kubernetes"]}}